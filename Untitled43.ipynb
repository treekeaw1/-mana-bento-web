{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/treekeaw1/-mana-bento-web/blob/main/Untitled43.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ---- 0. เตรียมไลบรารี ----\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import io\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from collections import Counter, defaultdict\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.preprocessing import MinMaxScaler, LabelEncoder\n",
        "from datetime import timedelta # เพิ่มเข้ามาสำหรับจัดการวันที่\n",
        "\n",
        "# ตรวจสอบและจัดการการ import Keras/TensorFlow\n",
        "# หาก Colab มีติดตั้ง TensorFlow อยู่แล้ว สามารถ import ได้เลย\n",
        "KERAS_AVAILABLE = False\n",
        "try:\n",
        "    import tensorflow as tf\n",
        "    from tensorflow.keras.models import Sequential\n",
        "    from tensorflow.keras.layers import LSTM, Dense, Embedding\n",
        "    from tensorflow.keras.utils import to_categorical\n",
        "    # ตรวจสอบเวอร์ชัน Keras (TensorFlow 2.x ใช้ Keras ในตัว)\n",
        "    if tf.__version__.startswith('2'):\n",
        "        print(f\"TensorFlow version {tf.__version__} is installed and Keras is available.\")\n",
        "        KERAS_AVAILABLE = True\n",
        "except ImportError:\n",
        "    print(\"TensorFlow/Keras not found. LSTM related functionalities will be skipped.\")\n",
        "\n",
        "import warnings\n",
        "\n",
        "# ปิด warning สำหรับ to_categorical (เป็นข้อควรระวังเรื่องค่าที่หายไป)\n",
        "# และ warning อื่นๆ ที่ไม่จำเป็น\n",
        "warnings.filterwarnings('ignore', category=FutureWarning, module='tensorflow')\n",
        "warnings.filterwarnings('ignore', category=UserWarning, module='keras')\n",
        "\n",
        "# --- ข้อมูล CSV ที่เราใช้มาตลอด (ข้อมูลใหม่ที่คุณให้มา) ---\n",
        "csv_content = \"\"\"วันที่,รางวัลที่ 1 (6 หลัก),เลข 2 ตัวล่าง\n",
        "2025/06/01,949256,91\n",
        "2025/06/16,507392,06\n",
        "2025/06/01,559352,20\n",
        "2025/05/16,251309,87\n",
        "2025/05/02,213388,06\n",
        "2025/04/16,266227,85\n",
        "2025/04/01,669687,36\n",
        "2025/03/16,757563,32\n",
        "2025/03/01,818894,54\n",
        "2025/02/16,847377,50\n",
        "2025/02/01,558700,51\n",
        "2025/01/17,807779,23\n",
        "2025/01/02,730209,51\n",
        "2024/12/16,097863,21\n",
        "2024/12/01,669843,61\n",
        "2024/11/16,187221,38\n",
        "2024/11/01,536044,32\n",
        "2024/10/16,482962,00\n",
        "2024/10/01,718665,59\n",
        "2024/09/16,608662,37\n",
        "2024/09/01,199606,94\n",
        "2024/08/16,095867,28\n",
        "2024/08/01,407041,46\n",
        "2024/07/16,367336,21\n",
        "2024/07/01,434503,89\n",
        "2024/06/16,518504,31\n",
        "2024/06/01,530593,42\n",
        "2024/05/16,205690,60\n",
        "2024/05/02,980116,17\n",
        "2024/04/16,943598,79\n",
        "2024/04/01,803481,90\n",
        "2024/03/16,997626,78\n",
        "2024/03/01,253603,79\n",
        "2024/02/16,941395,43\n",
        "2024/02/01,607063,09\n",
        "2024/01/17,105979,61\n",
        "2023/12/30,625544,89\n",
        "2023/12/16,356757,85\n",
        "2023/12/01,251097,91\n",
        "2023/11/16,557990,14\n",
        "2023/11/01,743951,63\n",
        "2023/10/16,931446,44\n",
        "2023/10/01,727202,66\n",
        "2023/09/16,320812,46\n",
        "2023/09/01,915478,91\n",
        "2023/08/16,471782,67\n",
        "2023/07/31,260453,11\n",
        "2023/07/16,169530,62\n",
        "2023/07/01,922605,16\n",
        "2023/06/16,264872,30\n",
        "2023/06/01,125272,09\n",
        "2023/05/16,132903,99\n",
        "2023/05/02,843019,65\n",
        "2023/04/16,984906,71\n",
        "2023/04/01,087907,99\n",
        "2023/03/16,025873,73\n",
        "2023/03/01,417652,55\n",
        "2023/02/16,590417,80\n",
        "2023/02/01,297411,92\n",
        "2023/01/17,812519,47\n",
        "2022/12/30,157196,58\n",
        "2022/12/16,845093,14\n",
        "2022/12/01,375805,08\n",
        "2022/11/16,121789,64\n",
        "2022/11/01,913106,70\n",
        "2022/10/16,613106,15\n",
        "2022/10/01,484669,50\n",
        "2022/09/16,943703,75\n",
        "2022/09/01,929332,83\n",
        "2022/08/16,331583,42\n",
        "2022/08/01,436594,14\n",
        "2022/07/16,620405,53\n",
        "2022/07/01,981417,61\n",
        "2022/06/16,361807,92\n",
        "2022/06/01,319196,02\n",
        "2022/05/16,155012,06\n",
        "2022/05/02,658642,09\n",
        "2022/04/16,395919,58\n",
        "2022/04/01,970618,10\n",
        "2022/03/16,737867,03\n",
        "2022/03/01,061905,07\n",
        "2022/02/17,098597,57\n",
        "2022/02/01,944308,30\n",
        "2022/01/17,880159,92\n",
        "2021/12/30,819068,36\n",
        "2021/12/16,639235,83\n",
        "2021/12/01,077258,82\n",
        "2021/11/16,032761,57\n",
        "2021/11/01,045037,95\n",
        "2021/10/16,386372,38\n",
        "2021/10/01,578171,83\n",
        "2021/09/16,070935,90\n",
        "2021/09/01,114475,79\n",
        "2021/08/16,046750,23\n",
        "2021/08/01,910261,69\n",
        "2021/07/16,556725,70\n",
        "2021/07/01,713517,29\n",
        "2021/06/16,691861,17\n",
        "2021/06/01,292972,45\n",
        "2021/05/16,684579,14\n",
        "2021/05/02,501272,18\n",
        "2021/04/16,100787,56\n",
        "2021/04/01,472270,05\n",
        "2021/03/16,890422,19\n",
        "2021/03/01,835538,73\n",
        "2021/02/16,424603,39\n",
        "2021/02/01,912307,97\n",
        "2021/01/17,384395,15\n",
        "2020/12/30,803628,19\n",
        "2020/12/16,201303,70\n",
        "2020/12/01,100994,84\n",
        "2020/11/16,972661,46\n",
        "2020/11/01,506404,40\n",
        "2020/10/16,286051,38\n",
        "2020/10/01,837893,59\n",
        "2020/09/16,244083,57\n",
        "2020/09/01,999997,98\n",
        "2020/08/16,945811,88\n",
        "2020/08/01,569391,92\n",
        "2020/07/16,873286,53\n",
        "2020/07/01,347258,83\n",
        "2020/06/16,516967,64\n",
        "2020/06/01,831567,24\n",
        "2020/04/01,051095,22\n",
        "2020/03/16,503446,77\n",
        "2020/03/01,875938,98\n",
        "2020/02/16,781403,94\n",
        "2020/02/01,589227,06\n",
        "2020/01/17,491774,68\n",
        "2019/12/30,510541,81\n",
        "2019/12/16,529924,97\n",
        "2019/12/01,453522,81\n",
        "2019/11/16,017223,32\n",
        "2019/11/01,967375,79\n",
        "2019/10/16,812564,15\n",
        "2019/10/01,691197,59\n",
        "2019/09/16,340388,85\n",
        "2019/09/01,798787,20\n",
        "2019/08/16,775476,89\n",
        "2019/08/01,387006,58\n",
        "2019/07/15,369765,88\n",
        "2019/07/01,943647,86\n",
        "2019/06/16,174055,29\n",
        "2019/06/01,516461,46\n",
        "2019/05/16,962526,71\n",
        "2019/05/02,061324,25\n",
        "2019/04/16,570331,23\n",
        "2019/04/01,109767,52\n",
        "2019/03/16,724628,64\n",
        "2019/03/01,345650,65\n",
        "2019/02/16,074824,56\n",
        "2019/02/01,967134,04\n",
        "2019/01/17,197079,65\n",
        "2018/12/30,735867,02\n",
        "2018/12/16,356564,62\n",
        "2018/12/01,021840,67\n",
        "2018/11/16,989903,16\n",
        "2018/11/01,149840,58\n",
        "2018/10/16,200515,93\n",
        "2018/10/01,452643,99\n",
        "2018/09/16,149760,79\n",
        "2018/09/01,734510,26\n",
        "2018/08/16,586117,10\n",
        "2018/08/01,386602,78\n",
        "2018/07/16,596324,27\n",
        "2018/07/01,963623,83\n",
        "2018/06/16,223131,46\n",
        "2018/06/01,988117,95\n",
        "2018/05/16,075629,20\n",
        "2018/05/02,248038,85\n",
        "2018/04/16,739229,60\n",
        "2018/04/01,412073,85\n",
        "2018/03/16,218559,82\n",
        "2018/03/02,759415,29\n",
        "2018/02/16,309915,39\n",
        "2018/02/01,026853,31\n",
        "2018/01/17,203823,50\n",
        "2017/12/30,911234,98\n",
        "2017/12/16,955596,89\n",
        "2017/12/01,451005,33\n",
        "2017/11/16,292391,98\n",
        "2017/11/01,533726,85\n",
        "2017/10/16,413494,86\n",
        "2017/10/01,880714,52\n",
        "2017/09/16,170143,71\n",
        "2017/09/01,143224,65\n",
        "2017/08/16,715431,37\n",
        "2017/08/01,756519,36\n",
        "2017/07/16,820327,87\n",
        "2017/07/01,112360,26\n",
        "2017/06/16,943142,47\n",
        "2017/06/01,053630,61\n",
        "2017/05/16,454891,53\n",
        "2017/05/02,008656,35\n",
        "2017/04/16,816729,40\n",
        "2017/04/01,392785,80\n",
        "2017/03/16,273863,92\n",
        "2017/03/01,978453,78\n",
        "2017/02/16,229116,14\n",
        "2017/02/01,054672,42\n",
        "2017/01/17,145157,25\n",
        "2016/12/30,377712,46\n",
        "2016/12/16,435286,35\n",
        "2016/12/01,086069,77\n",
        "2016/11/16,858383,44\n",
        "2016/11/01,785438,86\n",
        "2016/10/16,571947,98\n",
        "2016/10/01,887102,33\n",
        "2016/09/16,240650,42\n",
        "2016/09/01,638684,62\n",
        "2016/08/16,254004,33\n",
        "2016/08/01,272932,57\n",
        "2016/07/16,449764,55\n",
        "2016/07/01,082460,53\n",
        "2016/06/16,073816,79\n",
        "2016/06/01,511825,14\n",
        "2016/05/16,141737,98\n",
        "2016/05/02,399459,02\n",
        "2016/04/16,221609,87\n",
        "2016/04/01,066720,92\n",
        "2016/03/16,134918,32\n",
        "2016/03/01,439686,06\n",
        "2016/02/16,356364,98\n",
        "2016/02/01,927800,09\n",
        "2016/01/17,304371,50\n",
        "2015/12/30,008217,02\n",
        "2015/12/17,930255,08\n",
        "2015/12/01,915350,78\n",
        "2015/11/16,795283,03\n",
        "2015/11/01,361211,45\n",
        "2015/10/16,968630,62\n",
        "2015/10/01,594825,07\n",
        "2015/09/16,743148,06\n",
        "2015/09/01,021094,89\n",
        "2015/08/16,033363,40\n",
        "2015/08/01,518677,53\n",
        "2015/07/16,121507,49\n",
        "2015/07/01,759049,26\n",
        "2015/06/16,644742,05\n",
        "2015/06/02,388881,65\n",
        "2015/05/16,011421,38\n",
        "2015/05/02,543466,30\n",
        "2015/04/16,506260,38\n",
        "2015/04/01,605704,70\n",
        "2015/03/16,048151,92\n",
        "2015/03/01,240237,34\n",
        "2015/02/16,001864,90\n",
        "2015/02/01,155537,79\n",
        "2015/01/16,244351,74\n",
        "2014/12/30,461704,57\n",
        "2014/12/16,948354,90\n",
        "2014/12/01,480449,11\n",
        "2014/11/16,479804,25\n",
        "2014/11/01,206608,44\n",
        "2014/10/16,656409,94\n",
        "2014/10/01,375615,44\n",
        "2014/09/16,772269,35\n",
        "2014/09/01,856763,22\n",
        "2014/08/16,662842,91\n",
        "2014/08/01,766391,82\n",
        "2014/07/16,468728,45\n",
        "2014/07/01,378477,39\n",
        "2014/06/16,673920,95\n",
        "2014/06/01,781198,18\n",
        "2014/05/16,087523,20\n",
        "2014/05/02,103297,52\n",
        "2014/04/16,153406,26\n",
        "2014/04/01,028866,95\n",
        "2014/03/16,531404,79\n",
        "2014/03/01,906318,35\n",
        "2014/02/16,384245,01\n",
        "2014/02/01,180149,95\n",
        "2014/01/16,306902,52\n",
        "2013/12/30,561072,48\n",
        "2013/12/16,341767,79\n",
        "2013/12/01,168795,27\n",
        "2013/11/16,806925,28\n",
        "2013/11/01,739804,47\n",
        "2013/10/16,963289,60\n",
        "2013/10/01,647882,14\n",
        "2013/09/16,562684,63\n",
        "2013/09/01,548123,05\n",
        "2013/08/16,321327,20\n",
        "2013/08/01,356435,82\n",
        "2013/07/16,566996,86\n",
        "2013/07/01,646905,51\n",
        "2013/06/16,289673,69\n",
        "2013/06/01,935489,90\n",
        "2013/05/16,687125,56\n",
        "2013/05/02,603458,07\n",
        "2013/04/16,843846,86\n",
        "2013/04/01,571688,53\n",
        "2013/03/16,968433,52\n",
        "2013/03/01,976241,37\n",
        "2013/02/16,368257,09\n",
        "2013/02/01,565566,66\n",
        "2013/01/16,820981,08\n",
        "2012/12/30,302358,00\n",
        "2012/12/16,529524,72\n",
        "2012/12/01,110443,43\n",
        "2012/11/16,639500,15\n",
        "2012/11/01,524694,63\n",
        "2012/10/16,281343,28\n",
        "2012/10/01,124025,58\n",
        "2012/09/16,540143,79\n",
        "2012/09/01,329997,07\n",
        "2012/08/16,683877,28\n",
        "2012/08/01,895590,50\n",
        "2012/07/16,904050,11\n",
        "2012/07/01,915900,60\n",
        "2012/06/16,159373,51\n",
        "2012/06/01,882727,38\n",
        "2012/05/16,814418,31\n",
        "2012/05/02,889501,29\n",
        "2012/04/16,583470,62\n",
        "2012/04/01,257562,69\n",
        "2012/03/16,607064,08\n",
        "2012/03/01,222518,79\n",
        "2012/02/16,648684,18\n",
        "2012/02/01,320605,32\n",
        "2012/01/16,451445,81\n",
        "2011/12/30,526402,65\n",
        "2011/12/16,884178,21\n",
        "2011/12/01,408147,02\n",
        "2011/11/16,997777,57\n",
        "2011/11/01,805540,54\n",
        "2011/10/16,955756,83\n",
        "2011/10/01,511052,15\n",
        "2011/09/16,731198,28\n",
        "2011/09/01,724533,85\n",
        "2011/08/16,536960,62\n",
        "2011/08/01,218756,12\n",
        "2011/07/16,116556,12\n",
        "2011/07/01,622953,51\n",
        "2011/06/16,351276,88\n",
        "2011/06/01,562370,46\n",
        "2011/05/16,406417,05\n",
        "2011/05/02,054136,85\n",
        "2011/04/16,825988,44\n",
        "2011/04/01,814931,01\n",
        "2011/03/16,593331,96\n",
        "2011/03/01,656037,97\n",
        "2011/02/16,481746,27\n",
        "2011/02/01,610089,55\n",
        "2011/01/16,281062,23\n",
        "2010/12/30,884112,49\n",
        "2010/12/16,334380,24\n",
        "2010/12/01,181752,09\n",
        "2010/11/16,813993,43\n",
        "2010/11/01,191100,59\n",
        "2010/10/16,621377,42\n",
        "2010/10/01,488372,02\n",
        "2010/09/16,017422,66\n",
        "2010/09/01,354656,11\n",
        "2010/08/16,911097,64\n",
        "2010/08/01,210008,10\n",
        "2010/07/16,180387,34\n",
        "2010/07/01,480239,68\n",
        "2010/06/16,500104,73\n",
        "2010/06/01,444874,81\n",
        "2010/05/16,480012,12\n",
        "2010/05/02,360371,06\n",
        "2010/04/16,211743,96\n",
        "2010/04/01,959517,22\n",
        "2010/03/16,364222,97\n",
        "2010/03/01,215227,97\n",
        "2010/02/16,133707,03\n",
        "2010/02/01,186312,14\n",
        "2010/01/16,073577,67\n",
        "2009/12/30,994304,87\n",
        "2009/12/16,685141,05\n",
        "2009/12/01,776980,59\n",
        "2009/11/16,055986,58\n",
        "2009/11/01,689140,85\n",
        "2009/10/16,258487,00\n",
        "2009/10/01,169387,06\n",
        "2009/09/16,202912,48\n",
        "2009/09/01,015865,32\n",
        "2009/08/16,462933,96\n",
        "2009/08/01,154986,92\n",
        "2009/07/16,000816,94\n",
        "2009/07/01,207542,66\n",
        "2009/06/16,930456,15\n",
        "2009/06/01,777661,26\n",
        "2009/05/16,111411,54\n",
        "2009/05/02,294452,11\n",
        "2009/04/16,368415,33\n",
        "2009/04/01,816578,50\n",
        "2009/03/16,268812,36\n",
        "2009/03/01,553091,67\n",
        "2009/02/16,038730,93\n",
        "2009/02/01,534533,69\n",
        "2009/01/16,743212,25\n",
        "2008/12/30,218596,22\n",
        "2008/12/16,074114,25\n",
        "2008/12/01,205434,05\n",
        "2008/11/16,002612,20\n",
        "2008/11/01,272028,76\n",
        "2008/10/16,431277,98\n",
        "2008/10/01,882911,67\n",
        "2008/09/16,012377,56\n",
        "2008/09/01,695993,09\n",
        "2008/08/16,380377,36\n",
        "2008/08/01,850348,11\n",
        "2008/07/16,257374,41\n",
        "2008/07/01,943671,50\n",
        "2008/06/16,729111,75\n",
        "2008/06/01,414875,35\n",
        "2008/05/16,329231,69\n",
        "2008/05/02,453011,62\n",
        "2008/04/16,982800,64\n",
        "2008/04/01,012653,71\n",
        "2008/03/16,074946,33\n",
        "2008/03/01,936685,05\n",
        "2008/02/16,137054,80\n",
        "2008/02/01,212684,26\n",
        "2008/01/16,556010,81\n",
        "2007/12/30,595411,81\n",
        "2007/12/16,513501,96\n",
        "2007/12/01,113410,18\n",
        "2007/11/16,562481,73\n",
        "2007/11/01,927907,88\n",
        "2007/10/16,032988,48\n",
        "2007/10/01,430667,76\n",
        "2007/09/16,499336,45\n",
        "2007/09/01,331810,69\n",
        "2007/08/16,476207,93\n",
        "2007/08/01,429924,29\n",
        "2007/07/16,527384,77\n",
        "2007/07/01,565151,76\n",
        "2007/06/16,393194,41\n",
        "2007/06/01,836393,05\n",
        "2007/05/16,232897,25\n",
        "2007/05/02,430374,81\n",
        "2007/04/16,405105,63\n",
        "2007/04/01,622780,93\n",
        "2007/03/16,876763,85\n",
        "2007/03/01,742425,61\n",
        "2007/02/16,229116,14\n",
        "2007/02/01,054672,42\n",
        "2007/01/17,145157,25\n",
        "2006/12/30,377712,46\n",
        "2006/12/16,435286,35\n",
        "2006/12/01,086069,77\n",
        "2006/11/16,858383,44\n",
        "2006/11/01,785438,86\n",
        "2006/10/16,571947,98\n",
        "2006/10/01,887102,33\n",
        "2006/09/16,240650,42\n",
        "2006/09/01,638684,62\n",
        "2006/08/16,254004,33\n",
        "2006/08/01,272932,57\n",
        "2006/07/16,449764,55\n",
        "2006/07/01,082460,53\n",
        "2006/06/16,073816,79\n",
        "2006/06/01,511825,14\n",
        "2006/05/16,141737,98\n",
        "2006/05/02,399459,02\n",
        "2006/04/16,221609,87\n",
        "2006/04/01,066720,92\n",
        "2006/03/16,134918,32\n",
        "2006/03/01,439686,06\n",
        "2006/02/16,356364,98\n",
        "2006/02/01,927800,09\n",
        "2006/01/16,304371,50\n",
        "2005/12/30,008217,02\n",
        "2005/12/17,930255,08\n",
        "2005/12/01,915350,78\n",
        "2005/11/16,795283,03\n",
        "2005/11/01,361211,45\n",
        "2005/10/16,968630,62\n",
        "2005/10/01,594825,07\n",
        "2005/09/16,743148,06\n",
        "2005/09/01,021094,89\n",
        "2005/08/16,033363,40\n",
        "2005/08/01,518677,53\n",
        "2005/07/16,121507,49\n",
        "2005/07/01,759049,26\n",
        "2005/06/16,644742,05\n",
        "2005/06/02,388881,65\n",
        "2005/05/16,011421,38\n",
        "2005/05/02,543466,30\n",
        "2005/04/16,506260,38\n",
        "2005/04/01,605704,70\n",
        "2005/03/16,048151,92\n",
        "2005/03/01,240237,34\n",
        "2005/02/16,001864,90\n",
        "2005/02/01,155537,79\n",
        "2005/01/16,244351,74\n",
        "2004/12/30,461704,57\n",
        "2004/12/16,948354,90\n",
        "2004/12/01,480449,11\n",
        "2004/11/16,479804,25\n",
        "2004/11/01,206608,44\n",
        "2004/10/16,656409,94\n",
        "2004/10/01,375615,44\n",
        "2004/09/16,772269,35\n",
        "2004/09/01,856763,22\n",
        "2004/08/16,662842,91\n",
        "2004/08/01,766391,82\n",
        "2004/07/16,468728,45\n",
        "2004/07/01,378477,39\n",
        "2004/06/16,673920,95\n",
        "2004/06/01,781198,18\n",
        "2004/05/16,087523,20\n",
        "2004/05/02,103297,52\n",
        "2004/04/16,153406,26\n",
        "2004/04/01,028866,95\n",
        "2004/03/16,531404,79\n",
        "2004/03/01,906318,35\n",
        "2004/02/16,384245,01\n",
        "2004/02/01,180149,95\n",
        "2004/01/16,306902,52\n",
        "2003/12/30,561072,48\n",
        "2003/12/16,341767,79\n",
        "2003/12/01,168795,27\n",
        "2003/11/16,238511,68\n",
        "2003/11/01,941438,47\n",
        "2003/10/16,305500,03\n",
        "2003/10/01,912040,43\n",
        "2003/09/16,600589,53\n",
        "2003/09/01,187813,92\n",
        "2003/08/16,354771,00\n",
        "2003/08/01,766098,91\n",
        "2003/07/16,679545,75\n",
        "\"\"\"\n",
        "\n",
        "# --- คลาส LotteryDataProcessor ที่ปรับปรุงใหม่ ---\n",
        "class LotteryDataProcessor:\n",
        "    def __init__(self):\n",
        "        pass\n",
        "\n",
        "    def _get_digit_sum_and_parity(self, number_str):\n",
        "        \"\"\"คำนวณผลรวมของหลัก และตรวจสอบว่าเป็นคู่หรือคี่\"\"\"\n",
        "        digits = [int(d) for d in str(number_str) if d.isdigit()]\n",
        "        s = sum(digits)\n",
        "        return s, 'even' if s % 2 == 0 else 'odd'\n",
        "\n",
        "    def _get_digit_frequency(self, number_str):\n",
        "        \"\"\"นับความถี่ของแต่ละหลักในตัวเลข\"\"\"\n",
        "        freq = {str(i): 0 for i in range(10)}\n",
        "        for d in str(number_str):\n",
        "            if d.isdigit():\n",
        "                freq[d] += 1\n",
        "        return freq\n",
        "\n",
        "    def _get_consecutive_count(self, number_str):\n",
        "        \"\"\"นับจำนวนตัวเลขที่เรียงติดกัน (เช่น 12, 23)\"\"\"\n",
        "        s_num = str(number_str)\n",
        "        count = 0\n",
        "        for i in range(len(s_num) - 1):\n",
        "            if int(s_num[i+1]) - int(s_num[i]) == 1:\n",
        "                count += 1\n",
        "        return count\n",
        "\n",
        "    def _get_repeated_digit_count(self, number_str):\n",
        "        \"\"\"นับจำนวนตัวเลขที่ซ้ำกัน (เช่น 11, 344)\"\"\"\n",
        "        s_num = str(number_str)\n",
        "        counts = {}\n",
        "        for d in s_num:\n",
        "            if d.isdigit():\n",
        "                counts[d] = counts.get(d, 0) + 1\n",
        "        return sum(1 for d in counts if counts[d] > 1)\n",
        "\n",
        "    def generate_features(self, df_raw_data, window_size=8):\n",
        "        \"\"\"\n",
        "        สร้างฟีเจอร์เชิงลึกจากข้อมูล DataFrame ที่ประมวลผลแล้ว\n",
        "        โดยพิจารณาข้อมูลในอดีต (window_size)\n",
        "        \"\"\"\n",
        "        if df_raw_data.empty:\n",
        "            return pd.DataFrame()\n",
        "\n",
        "        feature_list = []\n",
        "\n",
        "        # Make sure data is sorted by date\n",
        "        df = df_raw_data.sort_values(by='date', ascending=True).copy()\n",
        "\n",
        "        for i in range(len(df)):\n",
        "            current_entry = df.iloc[i]\n",
        "\n",
        "            # ดึงข้อมูลย้อนหลังตาม window_size\n",
        "            # เราจะใช้ข้อมูลจากงวดก่อนหน้าถึงงวดที่ i-1 สำหรับ feature ที่เป็น cumulative/historical\n",
        "            start_idx = max(0, i - window_size)\n",
        "            window_data = df.iloc[start_idx:i] # ไม่รวมงวดปัจจุบัน\n",
        "\n",
        "            features = {\n",
        "                'draw_date': current_entry['date'],\n",
        "                'full_prize_1': current_entry['prize1'],\n",
        "                'bottom2_full': current_entry['bottom2'], # เปลี่ยนชื่อให้ชัดเจน\n",
        "                'prize1_3d_full': current_entry['prize1_3d'], # ใช้ prize1_3d ที่เตรียมไว้แล้ว\n",
        "            }\n",
        "\n",
        "            # --- Features สำหรับเลข 2 ตัวล่าง (Current Draw) ---\n",
        "            # ใช้ current_entry['bottom2'] แทน 'two_digit_bottom'\n",
        "            sum_2d, parity_2d = self._get_digit_sum_and_parity(current_entry['bottom2'])\n",
        "            features['2d_sum'] = sum_2d\n",
        "            features['2d_parity'] = 1 if parity_2d == 'even' else 0 # แปลงเป็นตัวเลข\n",
        "            features['2d_consecutive_count'] = self._get_consecutive_count(current_entry['bottom2'])\n",
        "            features['2d_repeated_digit_count'] = self._get_repeated_digit_count(current_entry['bottom2'])\n",
        "\n",
        "            # --- Features สำหรับเลขท้าย 3 ตัว (รางวัลที่ 1) (Current Draw) ---\n",
        "            # ใช้ current_entry['prize1_3d'] แทน 'three_digit_top'\n",
        "            sum_3d, parity_3d = self._get_digit_sum_and_parity(current_entry['prize1_3d'])\n",
        "            features['3d_sum'] = sum_3d\n",
        "            features['3d_parity'] = 1 if parity_3d == 'even' else 0 # แปลงเป็นตัวเลข\n",
        "            features['3d_consecutive_count'] = self._get_consecutive_count(current_entry['prize1_3d'])\n",
        "            features['3d_repeated_digit_count'] = self._get_repeated_digit_count(current_entry['prize1_3d'])\n",
        "\n",
        "            # --- Cumulative Features จากข้อมูลย้อนหลัง (ถ้ามี) ---\n",
        "            if not window_data.empty:\n",
        "                # Cumulative features for 2D\n",
        "                features['avg_2d_sum_prev_window'] = window_data['bottom2'].apply(lambda x: self._get_digit_sum_and_parity(x)[0]).mean()\n",
        "                features['std_2d_sum_prev_window'] = window_data['bottom2'].apply(lambda x: self._get_digit_sum_and_parity(x)[0]).std()\n",
        "                features['2d_even_parity_ratio_prev_window'] = (window_data['bottom2'].apply(lambda x: self._get_digit_sum_and_parity(x)[1] == 'even')).mean()\n",
        "\n",
        "                # Cumulative features for 3D\n",
        "                features['avg_3d_sum_prev_window'] = window_data['prize1_3d'].apply(lambda x: self._get_digit_sum_and_parity(x)[0]).mean()\n",
        "                features['std_3d_sum_prev_window'] = window_data['prize1_3d'].apply(lambda x: self._get_digit_sum_and_parity(x)[0]).std()\n",
        "                features['3d_even_parity_ratio_prev_window'] = (window_data['prize1_3d'].apply(lambda x: self._get_digit_sum_and_parity(x)[1] == 'even')).mean()\n",
        "\n",
        "                # --- Frequency of individual digits in previous window ---\n",
        "                # สำหรับ 2D\n",
        "                all_2d_digits = ''.join(str(x) for x in window_data['bottom2'])\n",
        "                freq_2d_digits = self._get_digit_frequency(all_2d_digits)\n",
        "                for d in range(10):\n",
        "                    features[f'2d_digit_{d}_freq_prev_window'] = freq_2d_digits.get(str(d), 0)\n",
        "\n",
        "                # สำหรับ 3D\n",
        "                all_3d_digits = ''.join(str(x) for x in window_data['prize1_3d'])\n",
        "                freq_3d_digits = self._get_digit_frequency(all_3d_digits)\n",
        "                for d in range(10):\n",
        "                    features[f'3d_digit_{d}_freq_prev_window'] = freq_3d_digits.get(str(d), 0)\n",
        "\n",
        "            else: # ถ้าไม่มีข้อมูลย้อนหลัง (งวดแรกๆ) ให้ใส่ค่า 0 หรือ NaN\n",
        "                features['avg_2d_sum_prev_window'] = 0\n",
        "                features['std_2d_sum_prev_window'] = 0\n",
        "                features['2d_even_parity_ratio_prev_window'] = 0\n",
        "                features['avg_3d_sum_prev_window'] = 0\n",
        "                features['std_3d_sum_prev_window'] = 0\n",
        "                features['3d_even_parity_ratio_prev_window'] = 0\n",
        "                for d in range(10):\n",
        "                    features[f'2d_digit_{d}_freq_prev_window'] = 0\n",
        "                    features[f'3d_digit_{d}_freq_prev_window'] = 0\n",
        "\n",
        "            feature_list.append(features)\n",
        "\n",
        "        # สร้าง DataFrame จาก feature_list\n",
        "        features_df = pd.DataFrame(feature_list)\n",
        "\n",
        "        # แทนที่ค่า NaN ที่อาจเกิดจาก std() ของข้อมูลน้อย\n",
        "        features_df = features_df.fillna(0) # หรือใช้ features_df.replace([np.inf, -np.inf], np.nan).fillna(0) ถ้ามีค่า inf\n",
        "\n",
        "        return features_df\n",
        "\n",
        "# ---- 1. โหลดข้อมูลและประมวลผลเบื้องต้น (ย้ายส่วนนี้จากด้านล่างขึ้นมา) ----\n",
        "df_raw = pd.read_csv(io.StringIO(csv_content.strip()), header=0)\n",
        "df_raw.columns = ['date','prize1','bottom2']\n",
        "\n",
        "df_raw['prize1'] = df_raw['prize1'].astype(str).str.zfill(6)\n",
        "df_raw['bottom2'] = df_raw['bottom2'].astype(str).str.zfill(2)\n",
        "\n",
        "df_raw['date'] = pd.to_datetime(df_raw['date'], format='%Y/%m/%d')\n",
        "df_raw = df_raw.sort_values(by='date', ascending=True).reset_index(drop=True)\n",
        "\n",
        "df_raw['year'] = df_raw['date'].dt.year\n",
        "df_raw['month'] = df_raw['date'].dt.month\n",
        "df_raw['day'] = df_raw['date'].dt.day\n",
        "df_raw['prize1_3d'] = df_raw['prize1'].apply(lambda x: str(x)[-3:])\n",
        "\n",
        "# เพิ่มการเตรียมข้อมูลสำหรับเมธอดอื่นๆ (ยังคงทำเหมือนเดิม)\n",
        "# แตกตัวเลข 2 ตัวล่างเป็นหลักสิบและหลักหน่วย\n",
        "df_raw['bottom2_digit1'] = df_raw['bottom2'].apply(lambda x: int(x[0]))\n",
        "df_raw['bottom2_digit2'] = df_raw['bottom2'].apply(lambda x: int(x[1]))\n",
        "\n",
        "# แตกตัวเลข 3 ตัวท้ายรางวัลที่ 1 เป็นแต่ละหลัก\n",
        "df_raw['prize1_3d_digit1'] = df_raw['prize1_3d'].apply(lambda x: int(x[0]))\n",
        "df_raw['prize1_3d_digit2'] = df_raw['prize1_3d'].apply(lambda x: int(x[1]))\n",
        "df_raw['prize1_3d_digit3'] = df_raw['prize1_3d'].apply(lambda x: int(x[2]))\n",
        "\n",
        "print(\"Data loading and initial processing complete in Cell 0.\")\n",
        "print(df_raw.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S8tQCNYeUqfY",
        "outputId": "3ccf8144-d0be-4c2b-a405-a5e53519fa07"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TensorFlow version 2.18.0 is installed and Keras is available.\n",
            "Data loading and initial processing complete in Cell 0.\n",
            "        date  prize1 bottom2  year  month  day prize1_3d  bottom2_digit1  \\\n",
            "0 2003-07-16  679545      75  2003      7   16       545               7   \n",
            "1 2003-08-01  766098      91  2003      8    1       098               9   \n",
            "2 2003-08-16  354771      00  2003      8   16       771               0   \n",
            "3 2003-09-01  187813      92  2003      9    1       813               9   \n",
            "4 2003-09-16  600589      53  2003      9   16       589               5   \n",
            "\n",
            "   bottom2_digit2  prize1_3d_digit1  prize1_3d_digit2  prize1_3d_digit3  \n",
            "0               5                 5                 4                 5  \n",
            "1               1                 0                 9                 8  \n",
            "2               0                 7                 7                 1  \n",
            "3               2                 8                 1                 3  \n",
            "4               3                 5                 8                 9  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ---- 2. สร้าง Features ด้วย LotteryDataProcessor ----\n",
        "processor = LotteryDataProcessor()\n",
        "# กำหนด window_size ที่เหมาะสม เช่น 8 งวด (ประมาณ 4 เดือน) หรือมากกว่า\n",
        "# window_size หมายถึงจำนวนงวดที่มองย้อนหลังเพื่อคำนวณสถิติ\n",
        "WINDOW_SIZE = 8\n",
        "features_df = processor.generate_features(df_raw.copy(), window_size=WINDOW_SIZE)\n",
        "\n",
        "print(f\"\\nGenerated features with window_size = {WINDOW_SIZE}.\")\n",
        "print(features_df.head())\n",
        "# ลบคอลัมน์ที่ไม่ใช่ฟีเจอร์จริง ๆ ออกไป (draw_date, full_prize_1, bottom2_full, prize1_3d_full)\n",
        "print(f\"Total features generated: {len(features_df.columns) - 4}\")\n",
        "\n",
        "# ตรวจสอบว่ามี NaN เหลืออยู่หรือไม่ (ควรมีน้อยลงหรือไม่มีเลยหลังจาก fillna ใน LotteryDataProcessor)\n",
        "print(\"\\nNumber of NaN values per column after feature generation:\")\n",
        "print(features_df.isnull().sum()[features_df.isnull().sum() > 0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3BOQ0oBMUurf",
        "outputId": "88f88392-b60f-4ecf-bec1-f93d3ea35e35"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Generated features with window_size = 8.\n",
            "   draw_date full_prize_1 bottom2_full prize1_3d_full  2d_sum  2d_parity  \\\n",
            "0 2003-07-16       679545           75            545      12          1   \n",
            "1 2003-08-01       766098           91            098      10          1   \n",
            "2 2003-08-16       354771           00            771       0          1   \n",
            "3 2003-09-01       187813           92            813      11          0   \n",
            "4 2003-09-16       600589           53            589       8          1   \n",
            "\n",
            "   2d_consecutive_count  2d_repeated_digit_count  3d_sum  3d_parity  ...  \\\n",
            "0                     0                        0      14          1  ...   \n",
            "1                     0                        0      17          0  ...   \n",
            "2                     0                        1      15          0  ...   \n",
            "3                     0                        0      12          1  ...   \n",
            "4                     0                        0      22          1  ...   \n",
            "\n",
            "   2d_digit_5_freq_prev_window  3d_digit_5_freq_prev_window  \\\n",
            "0                            0                            0   \n",
            "1                            1                            2   \n",
            "2                            1                            2   \n",
            "3                            1                            2   \n",
            "4                            1                            2   \n",
            "\n",
            "   2d_digit_6_freq_prev_window  3d_digit_6_freq_prev_window  \\\n",
            "0                            0                            0   \n",
            "1                            0                            0   \n",
            "2                            0                            0   \n",
            "3                            0                            0   \n",
            "4                            0                            0   \n",
            "\n",
            "   2d_digit_7_freq_prev_window  3d_digit_7_freq_prev_window  \\\n",
            "0                            0                            0   \n",
            "1                            1                            0   \n",
            "2                            1                            0   \n",
            "3                            1                            2   \n",
            "4                            1                            2   \n",
            "\n",
            "   2d_digit_8_freq_prev_window  3d_digit_8_freq_prev_window  \\\n",
            "0                            0                            0   \n",
            "1                            0                            0   \n",
            "2                            0                            1   \n",
            "3                            0                            1   \n",
            "4                            0                            2   \n",
            "\n",
            "   2d_digit_9_freq_prev_window  3d_digit_9_freq_prev_window  \n",
            "0                            0                            0  \n",
            "1                            0                            0  \n",
            "2                            1                            1  \n",
            "3                            1                            1  \n",
            "4                            2                            1  \n",
            "\n",
            "[5 rows x 38 columns]\n",
            "Total features generated: 34\n",
            "\n",
            "Number of NaN values per column after feature generation:\n",
            "Series([], dtype: int64)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ---- 3. เตรียมข้อมูลสำหรับโมเดล (Scaling & Sequencing) ----\n",
        "\n",
        "# เลือกคอลัมน์ฟีเจอร์ที่ต้องการใช้สำหรับโมเดล\n",
        "# เราจะแยก 'draw_date', 'full_prize_1', 'bottom2_full', 'prize1_3d_full' ออกไป\n",
        "# เนื่องจากเป็นข้อมูลดิบหรือตัวแปรเป้าหมาย ไม่ใช่ฟีเจอร์สำหรับ input ของโมเดล\n",
        "feature_columns = [col for col in features_df.columns if col not in ['draw_date', 'full_prize_1', 'bottom2_full', 'prize1_3d_full']]\n",
        "data_for_model = features_df[feature_columns].copy()\n",
        "\n",
        "# ตรวจสอบและจัดการค่าอนันต์ (Infinity) หรือ NaN ที่อาจหลงเหลืออยู่\n",
        "data_for_model.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
        "data_for_model.fillna(0, inplace=True) # แทนที่ NaN ด้วย 0 หรือค่าเฉลี่ย/median ก็ได้\n",
        "\n",
        "# เตรียม Scaler\n",
        "scaler_features = MinMaxScaler()\n",
        "\n",
        "# ปรับสเกลข้อมูลฟีเจอร์ทั้งหมด\n",
        "scaled_data_for_model = scaler_features.fit_transform(data_for_model)\n",
        "\n",
        "# แปลงกลับเป็น DataFrame เพื่อให้จัดการง่ายขึ้น\n",
        "scaled_features_df = pd.DataFrame(scaled_data_for_model, columns=feature_columns)\n",
        "\n",
        "print(\"Data scaling complete for model input.\")\n",
        "print(scaled_features_df.head())\n",
        "print(f\"Shape of scaled_features_df: {scaled_features_df.shape}\")\n",
        "\n",
        "# --- การสร้าง Sequence สำหรับ LSTM ---\n",
        "# ฟังก์ชันสำหรับสร้าง sequence (X) และ target (y)\n",
        "def create_sequences(data, target_2d, target_3d_digits, sequence_length):\n",
        "    X, y_2d, y_3d_d1, y_3d_d2, y_3d_d3 = [], [], [], [], []\n",
        "    for i in range(len(data) - sequence_length):\n",
        "        X.append(data.iloc[i:(i + sequence_length)].values)\n",
        "\n",
        "        # Target for 2-digit bottom (next value)\n",
        "        y_2d.append(int(target_2d.iloc[i + sequence_length]))\n",
        "\n",
        "        # Target for 3-digit prize1 (next value) - each digit\n",
        "        y_3d_d1.append(target_3d_digits[i + sequence_length][0])\n",
        "        y_3d_d2.append(target_3d_digits[i + sequence_length][1])\n",
        "        y_3d_d3.append(target_3d_digits[i + sequence_length][2])\n",
        "\n",
        "    return np.array(X), np.array(y_2d), np.array(y_3d_d1), np.array(y_3d_d2), np.array(y_3d_d3)\n",
        "\n",
        "# กำหนดความยาวของ Sequence (จำนวนงวดที่ใช้มองย้อนหลังเพื่อทำนายงวดถัดไป)\n",
        "SEQUENCE_LENGTH = 10 # ตัวอย่าง: ใช้ 10 งวดก่อนหน้าในการทำนาย\n",
        "\n",
        "# เตรียม target data (ใช้ข้อมูลจาก df_raw ที่แตกหลักไว้แล้ว)\n",
        "# ตรวจสอบให้แน่ใจว่า df_raw มี 'bottom2', 'prize1_3d_digit1' ฯลฯ\n",
        "targets_2d = df_raw['bottom2'].astype(int) # ใช้ bottom2 เต็ม\n",
        "targets_3d_digits = df_raw[['prize1_3d_digit1', 'prize1_3d_digit2', 'prize1_3d_digit3']].values.tolist()\n",
        "\n",
        "# สร้าง Sequence และ Target\n",
        "X_lstm, y_bottom2_lstm, y_prize1_3d_d1_lstm, y_prize1_3d_d2_lstm, y_prize1_3d_d3_lstm = create_sequences(\n",
        "    scaled_features_df, targets_2d, targets_3d_digits, SEQUENCE_LENGTH\n",
        ")\n",
        "\n",
        "print(f\"\\nLSTM sequences created with sequence_length = {SEQUENCE_LENGTH}.\")\n",
        "print(f\"Shape of X_lstm: {X_lstm.shape}\") # (จำนวนตัวอย่าง, ความยาว Sequence, จำนวน Features)\n",
        "print(f\"Shape of y_bottom2_lstm: {y_bottom2_lstm.shape}\") # (จำนวนตัวอย่าง,)\n",
        "print(f\"Shape of y_prize1_3d_d1_lstm: {y_prize1_3d_d1_lstm.shape}\") # (จำนวนตัวอย่าง,)\n",
        "\n",
        "# ตัวอย่าง: แปลง y_bottom2_lstm ให้เป็น one-hot encoding สำหรับ LSTM Classification\n",
        "if KERAS_AVAILABLE:\n",
        "    # สำหรับ 2 ตัวล่าง (0-99)\n",
        "    y_bottom2_categorical = to_categorical(y_bottom2_lstm, num_classes=100)\n",
        "    print(f\"Shape of y_bottom2_categorical (one-hot): {y_bottom2_categorical.shape}\")\n",
        "\n",
        "    # สำหรับ 3 ตัวท้ายรางวัลที่ 1: แต่ละหลักต้องทำเป็น one-hot encoding แยกกัน\n",
        "    y_prize1_3d_d1_categorical = to_categorical(y_prize1_3d_d1_lstm, num_classes=10)\n",
        "    y_prize1_3d_d2_categorical = to_categorical(y_prize1_3d_d2_lstm, num_classes=10)\n",
        "    y_prize1_3d_d3_categorical = to_categorical(y_prize1_3d_d3_lstm, num_classes=10)\n",
        "\n",
        "    print(f\"Shape of y_prize1_3d_d1_categorical: {y_prize1_3d_d1_categorical.shape}\")\n",
        "\n",
        "else:\n",
        "    print(\"Skipping Keras specific data preparation as TensorFlow/Keras is not available.\")\n",
        "\n",
        "# --- เตรียมข้อมูลสำหรับ Random Forest (ไม่ใช่ Sequence) ---\n",
        "# Random Forest จะใช้ข้อมูลฟีเจอร์ที่ไม่ได้ทำเป็น sequence\n",
        "# เราจะใช้ scaled_features_df โดยตรง แต่เลื่อน target ออกไป 1 งวด\n",
        "# เพื่อให้ทำนายงวดถัดไปเหมือนกับ LSTM\n",
        "X_rf = scaled_features_df.iloc[:-1].values # ใช้ features_df จากงวดที่ 0 ถึงงวดรองสุดท้าย\n",
        "# Targets สำหรับ RF จะเป็นตัวเลขของงวดถัดไป\n",
        "y_rf_bottom2_d1 = df_raw['bottom2_digit1'].iloc[SEQUENCE_LENGTH:].values\n",
        "y_rf_bottom2_d2 = df_raw['bottom2_digit2'].iloc[SEQUENCE_LENGTH:].values\n",
        "y_rf_prize1_3d_d1 = df_raw['prize1_3d_digit1'].iloc[SEQUENCE_LENGTH:].values\n",
        "y_rf_prize1_3d_d2 = df_raw['prize1_3d_digit2'].iloc[SEQUENCE_LENGTH:].values\n",
        "y_rf_prize1_3d_d3 = df_raw['prize1_3d_digit3'].iloc[SEQUENCE_LENGTH:].values\n",
        "\n",
        "# ตรวจสอบให้แน่ใจว่า X_rf และ y_rf มีขนาดที่สอดคล้องกันหลังจากสร้าง sequence\n",
        "# จำนวนตัวอย่างของ RF ควรเท่ากับ X_lstm\n",
        "# Note: RF doesn't use SEQUENCE_LENGTH in its input X, but targets are aligned\n",
        "X_rf_aligned = scaled_features_df.iloc[SEQUENCE_LENGTH-1:-1].values # Aligned for targets\n",
        "\n",
        "print(\"\\nRandom Forest data prepared.\")\n",
        "print(f\"Shape of X_rf_aligned: {X_rf_aligned.shape}\")\n",
        "print(f\"Shape of y_rf_bottom2_d1: {y_rf_bottom2_d1.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pffsJ2xAU5Ae",
        "outputId": "81d7c1ca-f559-4c40-f7ae-981640d8e226"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data scaling complete for model input.\n",
            "     2d_sum  2d_parity  2d_consecutive_count  2d_repeated_digit_count  \\\n",
            "0  0.666667        1.0                   0.0                      0.0   \n",
            "1  0.555556        1.0                   0.0                      0.0   \n",
            "2  0.000000        1.0                   0.0                      1.0   \n",
            "3  0.611111        0.0                   0.0                      0.0   \n",
            "4  0.444444        1.0                   0.0                      0.0   \n",
            "\n",
            "     3d_sum  3d_parity  3d_consecutive_count  3d_repeated_digit_count  \\\n",
            "0  0.541667        1.0                   0.5                      1.0   \n",
            "1  0.666667        0.0                   0.0                      0.0   \n",
            "2  0.583333        0.0                   0.0                      1.0   \n",
            "3  0.458333        1.0                   0.0                      0.0   \n",
            "4  0.875000        1.0                   0.5                      0.0   \n",
            "\n",
            "   avg_2d_sum_prev_window  std_2d_sum_prev_window  ...  \\\n",
            "0                0.000000                0.000000  ...   \n",
            "1                0.941176                0.000000  ...   \n",
            "2                0.862745                0.219971  ...   \n",
            "3                0.575163                1.000000  ...   \n",
            "4                0.647059                0.864861  ...   \n",
            "\n",
            "   2d_digit_5_freq_prev_window  3d_digit_5_freq_prev_window  \\\n",
            "0                          0.0                     0.000000   \n",
            "1                          0.2                     0.285714   \n",
            "2                          0.2                     0.285714   \n",
            "3                          0.2                     0.285714   \n",
            "4                          0.2                     0.285714   \n",
            "\n",
            "   2d_digit_6_freq_prev_window  3d_digit_6_freq_prev_window  \\\n",
            "0                          0.0                          0.0   \n",
            "1                          0.0                          0.0   \n",
            "2                          0.0                          0.0   \n",
            "3                          0.0                          0.0   \n",
            "4                          0.0                          0.0   \n",
            "\n",
            "   2d_digit_7_freq_prev_window  3d_digit_7_freq_prev_window  \\\n",
            "0                         0.00                         0.00   \n",
            "1                         0.25                         0.00   \n",
            "2                         0.25                         0.00   \n",
            "3                         0.25                         0.25   \n",
            "4                         0.25                         0.25   \n",
            "\n",
            "   2d_digit_8_freq_prev_window  3d_digit_8_freq_prev_window  \\\n",
            "0                          0.0                          0.0   \n",
            "1                          0.0                          0.0   \n",
            "2                          0.0                          0.2   \n",
            "3                          0.0                          0.2   \n",
            "4                          0.0                          0.4   \n",
            "\n",
            "   2d_digit_9_freq_prev_window  3d_digit_9_freq_prev_window  \n",
            "0                          0.0                     0.000000  \n",
            "1                          0.0                     0.000000  \n",
            "2                          0.2                     0.142857  \n",
            "3                          0.2                     0.142857  \n",
            "4                          0.4                     0.142857  \n",
            "\n",
            "[5 rows x 34 columns]\n",
            "Shape of scaled_features_df: (525, 34)\n",
            "\n",
            "LSTM sequences created with sequence_length = 10.\n",
            "Shape of X_lstm: (515, 10, 34)\n",
            "Shape of y_bottom2_lstm: (515,)\n",
            "Shape of y_prize1_3d_d1_lstm: (515,)\n",
            "Shape of y_bottom2_categorical (one-hot): (515, 100)\n",
            "Shape of y_prize1_3d_d1_categorical: (515, 10)\n",
            "\n",
            "Random Forest data prepared.\n",
            "Shape of X_rf_aligned: (515, 34)\n",
            "Shape of y_rf_bottom2_d1: (515,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ---- 4. สร้างและฝึกโมเดล (Hybrid Approach) ----\n",
        "\n",
        "# แยกข้อมูลเป็น Training และ Testing sets\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# กำหนดสัดส่วนของข้อมูลสำหรับ Training (เช่น 80%)\n",
        "# เราจะแบ่งข้อมูลโดยใช้ index เพื่อให้ลำดับเวลาไม่ถูกทำลาย\n",
        "# ใช้ช่วงแรกของข้อมูลสำหรับ Training และช่วงหลังสำหรับ Testing\n",
        "data_length_lstm = X_lstm.shape[0]\n",
        "train_size_lstm = int(data_length_lstm * 0.8) # 80% สำหรับ Training\n",
        "\n",
        "X_train_lstm = X_lstm[:train_size_lstm]\n",
        "X_test_lstm = X_lstm[train_size_lstm:]\n",
        "\n",
        "# Targets สำหรับ LSTM\n",
        "y_bottom2_train_categorical = y_bottom2_categorical[:train_size_lstm]\n",
        "y_bottom2_test_categorical = y_bottom2_categorical[train_size_lstm:]\n",
        "\n",
        "y_prize1_3d_d1_train_categorical = y_prize1_3d_d1_categorical[:train_size_lstm]\n",
        "y_prize1_3d_d1_test_categorical = y_prize1_3d_d1_categorical[train_size_lstm:]\n",
        "\n",
        "y_prize1_3d_d2_train_categorical = y_prize1_3d_d2_categorical[:train_size_lstm]\n",
        "y_prize1_3d_d2_test_categorical = y_prize1_3d_d2_categorical[train_size_lstm:]\n",
        "\n",
        "y_prize1_3d_d3_train_categorical = y_prize1_3d_d3_categorical[:train_size_lstm]\n",
        "y_prize1_3d_d3_test_categorical = y_prize1_3d_d3_categorical[train_size_lstm:]\n",
        "\n",
        "print(f\"\\nData split into training and testing sets (LSTM):\")\n",
        "print(f\"X_train_lstm shape: {X_train_lstm.shape}, X_test_lstm shape: {X_test_lstm.shape}\")\n",
        "print(f\"y_bottom2_train_categorical shape: {y_bottom2_train_categorical.shape}\")\n",
        "\n",
        "# สำหรับ Random Forest (ใช้ X_rf_aligned ที่เตรียมไว้)\n",
        "data_length_rf = X_rf_aligned.shape[0]\n",
        "train_size_rf = int(data_length_rf * 0.8)\n",
        "\n",
        "X_train_rf = X_rf_aligned[:train_size_rf]\n",
        "X_test_rf = X_rf_aligned[train_size_rf:]\n",
        "\n",
        "y_rf_bottom2_d1_train = y_rf_bottom2_d1[:train_size_rf]\n",
        "y_rf_bottom2_d1_test = y_rf_bottom2_d1[train_size_rf:]\n",
        "\n",
        "y_rf_bottom2_d2_train = y_rf_bottom2_d2[:train_size_rf]\n",
        "y_rf_bottom2_d2_test = y_rf_bottom2_d2[train_size_rf:]\n",
        "\n",
        "y_rf_prize1_3d_d1_train = y_rf_prize1_3d_d1[:train_size_rf]\n",
        "y_rf_prize1_3d_d1_test = y_rf_prize1_3d_d1[train_size_rf:]\n",
        "\n",
        "y_rf_prize1_3d_d2_train = y_rf_prize1_3d_d2[:train_size_rf]\n",
        "y_rf_prize1_3d_d2_test = y_rf_prize1_3d_d2[train_size_rf:]\n",
        "\n",
        "y_rf_prize1_3d_d3_train = y_rf_prize1_3d_d3[:train_size_rf]\n",
        "y_rf_prize1_3d_d3_test = y_rf_prize1_3d_d3[train_size_rf:]\n",
        "\n",
        "print(f\"Data split into training and testing sets (Random Forest):\")\n",
        "print(f\"X_train_rf shape: {X_train_rf.shape}, X_test_rf shape: {X_test_rf.shape}\")\n",
        "\n",
        "\n",
        "# --- โมเดล 1: LSTM สำหรับทำนายเลข 2 ตัวล่าง (Classification 00-99) ---\n",
        "if KERAS_AVAILABLE:\n",
        "    model_bottom2_lstm = Sequential([\n",
        "        LSTM(128, activation='relu', return_sequences=True, input_shape=(X_train_lstm.shape[1], X_train_lstm.shape[2])), # เพิ่ม return_sequences\n",
        "        LSTM(64, activation='relu'), # เพิ่มอีกชั้น LSTM\n",
        "        Dense(100, activation='softmax') # Softmax สำหรับ Classification 00-99\n",
        "    ])\n",
        "\n",
        "    model_bottom2_lstm.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "    print(\"\\nLSTM Model for 2-Digit Bottom Summary:\")\n",
        "    model_bottom2_lstm.summary()\n",
        "\n",
        "    print(\"\\nTraining LSTM Model for 2-Digit Bottom...\")\n",
        "    history_bottom2 = model_bottom2_lstm.fit(\n",
        "        X_train_lstm, y_bottom2_train_categorical,\n",
        "        epochs=100, # เพิ่ม epochs เพื่อให้โมเดลเรียนรู้ได้มากขึ้น\n",
        "        batch_size=64, # ปรับ batch_size\n",
        "        validation_split=0.2, # แบ่งข้อมูล training ไปทำ validation\n",
        "        verbose=1\n",
        "    )\n",
        "\n",
        "    print(\"\\nEvaluation of LSTM Model for 2-Digit Bottom:\")\n",
        "    loss_bottom2, accuracy_bottom2 = model_bottom2_lstm.evaluate(X_test_lstm, y_bottom2_test_categorical, verbose=0)\n",
        "    print(f\"Test Loss (2-Digit Bottom): {loss_bottom2:.4f}\")\n",
        "    print(f\"Test Accuracy (2-Digit Bottom): {accuracy_bottom2:.4f}\")\n",
        "\n",
        "    # --- โมเดล 2: LSTM สำหรับทำนายเลขท้าย 3 ตัวรางวัลที่ 1 (แต่ละหลัก) ---\n",
        "    # สร้าง 3 โมเดล LSTM แยกกันสำหรับแต่ละหลัก เพื่อให้จัดการง่าย\n",
        "    print(\"\\nTraining separate LSTM models for each digit of Prize 1 (3D)...\")\n",
        "\n",
        "    # Model for Prize 1 (3D) - Digit 1 (หลักร้อย)\n",
        "    model_prize1_3d_digit1_lstm = Sequential([\n",
        "        LSTM(128, activation='relu', return_sequences=True, input_shape=(X_train_lstm.shape[1], X_train_lstm.shape[2])),\n",
        "        LSTM(64, activation='relu'),\n",
        "        Dense(10, activation='softmax') # 10 classes (0-9)\n",
        "    ])\n",
        "    model_prize1_3d_digit1_lstm.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "    print(\"\\nTraining LSTM Model for Prize 1 (3D) - Digit 1 (Hundred)...\")\n",
        "    history_digit1 = model_prize1_3d_digit1_lstm.fit(\n",
        "        X_train_lstm, y_prize1_3d_d1_train_categorical,\n",
        "        epochs=100, batch_size=64, validation_split=0.2, verbose=0 # ตั้ง verbose เป็น 0 เพื่อให้ output ไม่เยอะเกินไป\n",
        "    )\n",
        "    loss_d1, acc_d1 = model_prize1_3d_digit1_lstm.evaluate(X_test_lstm, y_prize1_3d_d1_test_categorical, verbose=0)\n",
        "    print(f\"Test Accuracy (Prize 1 - Digit 1): {acc_d1:.4f}\")\n",
        "\n",
        "    # Model for Prize 1 (3D) - Digit 2 (หลักสิบ)\n",
        "    model_prize1_3d_digit2_lstm = Sequential([\n",
        "        LSTM(128, activation='relu', return_sequences=True, input_shape=(X_train_lstm.shape[1], X_train_lstm.shape[2])),\n",
        "        LSTM(64, activation='relu'),\n",
        "        Dense(10, activation='softmax') # 10 classes (0-9)\n",
        "    ])\n",
        "    model_prize1_3d_digit2_lstm.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "    print(\"Training LSTM Model for Prize 1 (3D) - Digit 2 (Ten)...\")\n",
        "    history_digit2 = model_prize1_3d_digit2_lstm.fit(\n",
        "        X_train_lstm, y_prize1_3d_d2_train_categorical,\n",
        "        epochs=100, batch_size=64, validation_split=0.2, verbose=0\n",
        "    )\n",
        "    loss_d2, acc_d2 = model_prize1_3d_digit2_lstm.evaluate(X_test_lstm, y_prize1_3d_d2_test_categorical, verbose=0)\n",
        "    print(f\"Test Accuracy (Prize 1 - Digit 2): {acc_d2:.4f}\")\n",
        "\n",
        "    # Model for Prize 1 (3D) - Digit 3 (หลักหน่วย)\n",
        "    model_prize1_3d_digit3_lstm = Sequential([\n",
        "        LSTM(128, activation='relu', return_sequences=True, input_shape=(X_train_lstm.shape[1], X_train_lstm.shape[2])),\n",
        "        LSTM(64, activation='relu'),\n",
        "        Dense(10, activation='softmax') # 10 classes (0-9)\n",
        "    ])\n",
        "    model_prize1_3d_digit3_lstm.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "    print(\"Training LSTM Model for Prize 1 (3D) - Digit 3 (Unit)...\")\n",
        "    history_digit3 = model_prize1_3d_digit3_lstm.fit(\n",
        "        X_train_lstm, y_prize1_3d_d3_train_categorical,\n",
        "        epochs=100, batch_size=64, validation_split=0.2, verbose=0\n",
        "    )\n",
        "    loss_d3, acc_d3 = model_prize1_3d_digit3_lstm.evaluate(X_test_lstm, y_prize1_3d_d3_test_categorical, verbose=0)\n",
        "    print(f\"Test Accuracy (Prize 1 - Digit 3): {acc_d3:.4f}\")\n",
        "\n",
        "else:\n",
        "    print(\"Skipping LSTM model training as TensorFlow/Keras is not available.\")\n",
        "\n",
        "# --- โมเดล 3: Random Forest สำหรับทำนายเลขแต่ละหลัก (จาก Features แบบไม่เป็นลำดับ) ---\n",
        "print(\"\\nTraining separate Random Forest models for each digit...\")\n",
        "\n",
        "# โมเดล Random Forest สำหรับเลข 2 ตัวล่าง - หลักที่ 1\n",
        "rf_bottom2_d1_model = RandomForestClassifier(n_estimators=200, random_state=42, class_weight='balanced') # เพิ่ม n_estimators และ class_weight\n",
        "print(\"Training Random Forest for 2-Digit Bottom - Digit 1...\")\n",
        "rf_bottom2_d1_model.fit(X_train_rf, y_rf_bottom2_d1_train)\n",
        "rf_b2_d1_accuracy = rf_bottom2_d1_model.score(X_test_rf, y_rf_bottom2_d1_test)\n",
        "print(f\"Test Accuracy (RF 2-Digit Bottom - Digit 1): {rf_b2_d1_accuracy:.4f}\")\n",
        "\n",
        "# โมเดล Random Forest สำหรับเลข 2 ตัวล่าง - หลักที่ 2\n",
        "rf_bottom2_d2_model = RandomForestClassifier(n_estimators=200, random_state=42, class_weight='balanced')\n",
        "print(\"Training Random Forest for 2-Digit Bottom - Digit 2...\")\n",
        "rf_bottom2_d2_model.fit(X_train_rf, y_rf_bottom2_d2_train)\n",
        "rf_b2_d2_accuracy = rf_bottom2_d2_model.score(X_test_rf, y_rf_bottom2_d2_test)\n",
        "print(f\"Test Accuracy (RF 2-Digit Bottom - Digit 2): {rf_b2_d2_accuracy:.4f}\")\n",
        "\n",
        "# โมเดล Random Forest สำหรับเลขท้าย 3 ตัวรางวัลที่ 1 - หลักที่ 1\n",
        "rf_prize1_3d_d1_model = RandomForestClassifier(n_estimators=200, random_state=42, class_weight='balanced')\n",
        "print(\"Training Random Forest for Prize 1 (3D) - Digit 1...\")\n",
        "rf_prize1_3d_d1_model.fit(X_train_rf, y_rf_prize1_3d_d1_train)\n",
        "rf_p1_3d_d1_accuracy = rf_prize1_3d_d1_model.score(X_test_rf, y_rf_prize1_3d_d1_test)\n",
        "print(f\"Test Accuracy (RF Prize 1 (3D) - Digit 1): {rf_p1_3d_d1_accuracy:.4f}\")\n",
        "\n",
        "# โมเดล Random Forest สำหรับเลขท้าย 3 ตัวรางวัลที่ 1 - หลักที่ 2\n",
        "rf_prize1_3d_d2_model = RandomForestClassifier(n_estimators=200, random_state=42, class_weight='balanced')\n",
        "print(\"Training Random Forest for Prize 1 (3D) - Digit 2...\")\n",
        "rf_prize1_3d_d2_model.fit(X_train_rf, y_rf_prize1_3d_d2_train)\n",
        "rf_p1_3d_d2_accuracy = rf_prize1_3d_d2_model.score(X_test_rf, y_rf_prize1_3d_d2_test)\n",
        "print(f\"Test Accuracy (RF Prize 1 (3D) - Digit 2): {rf_p1_3d_d2_accuracy:.4f}\")\n",
        "\n",
        "# โมเดล Random Forest สำหรับเลขท้าย 3 ตัวรางวัลที่ 1 - หลักที่ 3\n",
        "rf_prize1_3d_d3_model = RandomForestClassifier(n_estimators=200, random_state=42, class_weight='balanced')\n",
        "print(\"Training Random Forest for Prize 1 (3D) - Digit 3...\")\n",
        "rf_prize1_3d_d3_model.fit(X_train_rf, y_rf_prize1_3d_d3_train)\n",
        "rf_p1_3d_d3_accuracy = rf_prize1_3d_d3_model.score(X_test_rf, y_rf_prize1_3d_d3_test)\n",
        "print(f\"Test Accuracy (RF Prize 1 (3D) - Digit 3): {rf_p1_3d_d3_accuracy:.4f}\")\n",
        "\n",
        "print(\"\\nModel training complete.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "VIQ8hEL5VCwG",
        "outputId": "be89ec04-9f7d-487b-8bc2-1554fe5fae08"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Data split into training and testing sets (LSTM):\n",
            "X_train_lstm shape: (412, 10, 34), X_test_lstm shape: (103, 10, 34)\n",
            "y_bottom2_train_categorical shape: (412, 100)\n",
            "Data split into training and testing sets (Random Forest):\n",
            "X_train_rf shape: (412, 34), X_test_rf shape: (103, 34)\n",
            "\n",
            "LSTM Model for 2-Digit Bottom Summary:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ lstm (\u001b[38;5;33mLSTM\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m128\u001b[0m)        │        \u001b[38;5;34m83,456\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ lstm_1 (\u001b[38;5;33mLSTM\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │        \u001b[38;5;34m49,408\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)            │         \u001b[38;5;34m6,500\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)        │        <span style=\"color: #00af00; text-decoration-color: #00af00\">83,456</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ lstm_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │        <span style=\"color: #00af00; text-decoration-color: #00af00\">49,408</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)            │         <span style=\"color: #00af00; text-decoration-color: #00af00\">6,500</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m139,364\u001b[0m (544.39 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">139,364</span> (544.39 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m139,364\u001b[0m (544.39 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">139,364</span> (544.39 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Training LSTM Model for 2-Digit Bottom...\n",
            "Epoch 1/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 187ms/step - accuracy: 0.0032 - loss: 4.6035 - val_accuracy: 0.0120 - val_loss: 4.6176\n",
            "Epoch 2/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.0164 - loss: 4.5853 - val_accuracy: 0.0120 - val_loss: 4.6385\n",
            "Epoch 3/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 0.0289 - loss: 4.5595 - val_accuracy: 0.0000e+00 - val_loss: 4.6914\n",
            "Epoch 4/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 0.0258 - loss: 4.5379 - val_accuracy: 0.0000e+00 - val_loss: 4.7938\n",
            "Epoch 5/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.0095 - loss: 4.5270 - val_accuracy: 0.0361 - val_loss: 4.7811\n",
            "Epoch 6/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 0.0405 - loss: 4.4668 - val_accuracy: 0.0120 - val_loss: 4.8083\n",
            "Epoch 7/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 0.0254 - loss: 4.4465 - val_accuracy: 0.0120 - val_loss: 4.8303\n",
            "Epoch 8/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.0437 - loss: 4.3987 - val_accuracy: 0.0000e+00 - val_loss: 4.8410\n",
            "Epoch 9/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.0291 - loss: 4.3071 - val_accuracy: 0.0241 - val_loss: 4.7707\n",
            "Epoch 10/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.0495 - loss: 4.3038 - val_accuracy: 0.0241 - val_loss: 5.0453\n",
            "Epoch 11/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.0447 - loss: 4.2004 - val_accuracy: 0.0241 - val_loss: 4.8397\n",
            "Epoch 12/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.0555 - loss: 4.1493 - val_accuracy: 0.0241 - val_loss: 4.7502\n",
            "Epoch 13/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.0833 - loss: 4.0612 - val_accuracy: 0.0120 - val_loss: 4.9758\n",
            "Epoch 14/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.1187 - loss: 3.8580 - val_accuracy: 0.0000e+00 - val_loss: 4.9803\n",
            "Epoch 15/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - accuracy: 0.1256 - loss: 3.7625 - val_accuracy: 0.0120 - val_loss: 5.0372\n",
            "Epoch 16/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.1068 - loss: 3.7367 - val_accuracy: 0.0241 - val_loss: 5.2426\n",
            "Epoch 17/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.1178 - loss: 3.6046 - val_accuracy: 0.0120 - val_loss: 5.2008\n",
            "Epoch 18/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - accuracy: 0.1703 - loss: 3.4903 - val_accuracy: 0.0241 - val_loss: 5.5570\n",
            "Epoch 19/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.1624 - loss: 3.3565 - val_accuracy: 0.0361 - val_loss: 5.5979\n",
            "Epoch 20/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.1323 - loss: 3.2251 - val_accuracy: 0.0000e+00 - val_loss: 5.6388\n",
            "Epoch 21/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.1871 - loss: 3.1880 - val_accuracy: 0.0000e+00 - val_loss: 5.8961\n",
            "Epoch 22/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 0.1751 - loss: 3.0776 - val_accuracy: 0.0482 - val_loss: 5.9666\n",
            "Epoch 23/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.2379 - loss: 2.8237 - val_accuracy: 0.0241 - val_loss: 6.1528\n",
            "Epoch 24/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.2145 - loss: 2.7658 - val_accuracy: 0.0241 - val_loss: 6.7515\n",
            "Epoch 25/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 0.2080 - loss: 2.6688 - val_accuracy: 0.0361 - val_loss: 6.3454\n",
            "Epoch 26/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.2338 - loss: 2.6888 - val_accuracy: 0.0000e+00 - val_loss: 6.4204\n",
            "Epoch 27/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.2429 - loss: 2.5132 - val_accuracy: 0.0000e+00 - val_loss: 7.0715\n",
            "Epoch 28/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.2619 - loss: 2.5870 - val_accuracy: 0.0120 - val_loss: 6.1185\n",
            "Epoch 29/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - accuracy: 0.2943 - loss: 2.3081 - val_accuracy: 0.0120 - val_loss: 7.9429\n",
            "Epoch 30/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.2588 - loss: 2.3899 - val_accuracy: 0.0000e+00 - val_loss: 6.2399\n",
            "Epoch 31/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.3530 - loss: 2.1231 - val_accuracy: 0.0241 - val_loss: 8.0582\n",
            "Epoch 32/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.3167 - loss: 2.0535 - val_accuracy: 0.0000e+00 - val_loss: 7.2861\n",
            "Epoch 33/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - accuracy: 0.3847 - loss: 1.9305 - val_accuracy: 0.0000e+00 - val_loss: 7.1994\n",
            "Epoch 34/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - accuracy: 0.4074 - loss: 1.8412 - val_accuracy: 0.0120 - val_loss: 8.0240\n",
            "Epoch 35/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - accuracy: 0.4691 - loss: 1.7258 - val_accuracy: 0.0120 - val_loss: 8.2154\n",
            "Epoch 36/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - accuracy: 0.4431 - loss: 1.7085 - val_accuracy: 0.0000e+00 - val_loss: 7.6531\n",
            "Epoch 37/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 84ms/step - accuracy: 0.4716 - loss: 1.6484 - val_accuracy: 0.0241 - val_loss: 8.3509\n",
            "Epoch 38/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 81ms/step - accuracy: 0.4615 - loss: 1.5651 - val_accuracy: 0.0241 - val_loss: 9.7807\n",
            "Epoch 39/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 0.4547 - loss: 1.6362 - val_accuracy: 0.0000e+00 - val_loss: 9.1360\n",
            "Epoch 40/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 42ms/step - accuracy: 0.4775 - loss: 1.4849 - val_accuracy: 0.0000e+00 - val_loss: 10.0917\n",
            "Epoch 41/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.5587 - loss: 1.3493 - val_accuracy: 0.0120 - val_loss: 9.4200\n",
            "Epoch 42/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 0.5657 - loss: 1.3021 - val_accuracy: 0.0000e+00 - val_loss: 9.7633\n",
            "Epoch 43/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.5503 - loss: 1.3205 - val_accuracy: 0.0000e+00 - val_loss: 8.8412\n",
            "Epoch 44/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.5289 - loss: 1.3400 - val_accuracy: 0.0241 - val_loss: 10.7795\n",
            "Epoch 45/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 0.6161 - loss: 1.1211 - val_accuracy: 0.0241 - val_loss: 12.1804\n",
            "Epoch 46/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.6336 - loss: 1.0740 - val_accuracy: 0.0000e+00 - val_loss: 11.2369\n",
            "Epoch 47/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.6351 - loss: 1.0497 - val_accuracy: 0.0241 - val_loss: 11.0469\n",
            "Epoch 48/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.6949 - loss: 0.8556 - val_accuracy: 0.0120 - val_loss: 12.2060\n",
            "Epoch 49/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 0.6972 - loss: 0.7986 - val_accuracy: 0.0120 - val_loss: 14.3158\n",
            "Epoch 50/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.7320 - loss: 0.7538 - val_accuracy: 0.0602 - val_loss: 12.7447\n",
            "Epoch 51/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.7016 - loss: 0.9074 - val_accuracy: 0.0361 - val_loss: 14.7996\n",
            "Epoch 52/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.7108 - loss: 0.9636 - val_accuracy: 0.0241 - val_loss: 11.4814\n",
            "Epoch 53/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 0.7330 - loss: 0.8828 - val_accuracy: 0.0000e+00 - val_loss: 10.6434\n",
            "Epoch 54/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.6955 - loss: 0.8166 - val_accuracy: 0.0000e+00 - val_loss: 12.4222\n",
            "Epoch 55/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - accuracy: 0.7844 - loss: 0.6559 - val_accuracy: 0.0120 - val_loss: 12.9997\n",
            "Epoch 56/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 0.7901 - loss: 0.6122 - val_accuracy: 0.0241 - val_loss: 14.6151\n",
            "Epoch 57/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - accuracy: 0.8122 - loss: 0.5376 - val_accuracy: 0.0000e+00 - val_loss: 15.9671\n",
            "Epoch 58/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.8298 - loss: 0.5300 - val_accuracy: 0.0241 - val_loss: 16.2892\n",
            "Epoch 59/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.8395 - loss: 0.5089 - val_accuracy: 0.0120 - val_loss: 16.0271\n",
            "Epoch 60/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - accuracy: 0.7972 - loss: 0.6017 - val_accuracy: 0.0361 - val_loss: 15.7343\n",
            "Epoch 61/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.8065 - loss: 0.6185 - val_accuracy: 0.0120 - val_loss: 13.6371\n",
            "Epoch 62/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.8162 - loss: 0.5793 - val_accuracy: 0.0120 - val_loss: 16.3299\n",
            "Epoch 63/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 0.8675 - loss: 0.4654 - val_accuracy: 0.0000e+00 - val_loss: 14.0668\n",
            "Epoch 64/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.8602 - loss: 0.3652 - val_accuracy: 0.0241 - val_loss: 15.6122\n",
            "Epoch 65/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.7687 - loss: 0.7415 - val_accuracy: 0.0000e+00 - val_loss: 14.8494\n",
            "Epoch 66/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - accuracy: 0.6733 - loss: 0.9685 - val_accuracy: 0.0361 - val_loss: 13.1332\n",
            "Epoch 67/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 0.7278 - loss: 0.8840 - val_accuracy: 0.0120 - val_loss: 11.8878\n",
            "Epoch 68/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.7482 - loss: 0.7190 - val_accuracy: 0.0000e+00 - val_loss: 11.3964\n",
            "Epoch 69/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.8381 - loss: 0.5659 - val_accuracy: 0.0000e+00 - val_loss: 14.1726\n",
            "Epoch 70/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.8578 - loss: 0.5026 - val_accuracy: 0.0000e+00 - val_loss: 15.4067\n",
            "Epoch 71/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - accuracy: 0.8820 - loss: 0.4422 - val_accuracy: 0.0120 - val_loss: 15.4964\n",
            "Epoch 72/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - accuracy: 0.8731 - loss: 0.4956 - val_accuracy: 0.0241 - val_loss: 14.6273\n",
            "Epoch 73/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - accuracy: 0.9193 - loss: 0.3842 - val_accuracy: 0.0361 - val_loss: 15.4541\n",
            "Epoch 74/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 80ms/step - accuracy: 0.9254 - loss: 0.2612 - val_accuracy: 0.0120 - val_loss: 15.7249\n",
            "Epoch 75/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 83ms/step - accuracy: 0.9410 - loss: 0.2041 - val_accuracy: 0.0241 - val_loss: 17.2691\n",
            "Epoch 76/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 81ms/step - accuracy: 0.9398 - loss: 0.2401 - val_accuracy: 0.0241 - val_loss: 18.8993\n",
            "Epoch 77/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 0.9387 - loss: 0.2138 - val_accuracy: 0.0241 - val_loss: 18.4131\n",
            "Epoch 78/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.9440 - loss: 0.2185 - val_accuracy: 0.0361 - val_loss: 18.5493\n",
            "Epoch 79/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.9588 - loss: 0.1502 - val_accuracy: 0.0000e+00 - val_loss: 19.7572\n",
            "Epoch 80/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - accuracy: 0.9624 - loss: 0.1502 - val_accuracy: 0.0120 - val_loss: 18.3059\n",
            "Epoch 81/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 48ms/step - accuracy: 0.9417 - loss: 0.2370 - val_accuracy: 0.0241 - val_loss: 19.3662\n",
            "Epoch 82/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.9505 - loss: 0.1874 - val_accuracy: 0.0361 - val_loss: 18.7249\n",
            "Epoch 83/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - accuracy: 0.9590 - loss: 0.1268 - val_accuracy: 0.0361 - val_loss: 19.8835\n",
            "Epoch 84/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 42ms/step - accuracy: 0.9610 - loss: 0.1445 - val_accuracy: 0.0361 - val_loss: 20.9830\n",
            "Epoch 85/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - accuracy: 0.9631 - loss: 0.1488 - val_accuracy: 0.0241 - val_loss: 20.9784\n",
            "Epoch 86/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 42ms/step - accuracy: 0.9607 - loss: 0.1462 - val_accuracy: 0.0361 - val_loss: 19.1326\n",
            "Epoch 87/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.9486 - loss: 0.1478 - val_accuracy: 0.0241 - val_loss: 20.3023\n",
            "Epoch 88/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 0.9574 - loss: 0.1336 - val_accuracy: 0.0361 - val_loss: 20.7326\n",
            "Epoch 89/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - accuracy: 0.9619 - loss: 0.1349 - val_accuracy: 0.0361 - val_loss: 20.7982\n",
            "Epoch 90/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - accuracy: 0.9623 - loss: 0.0976 - val_accuracy: 0.0241 - val_loss: 22.1472\n",
            "Epoch 91/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - accuracy: 0.9689 - loss: 0.0926 - val_accuracy: 0.0241 - val_loss: 22.7971\n",
            "Epoch 92/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 0.9631 - loss: 0.1019 - val_accuracy: 0.0361 - val_loss: 23.1438\n",
            "Epoch 93/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 0.9574 - loss: 0.1426 - val_accuracy: 0.0241 - val_loss: 22.5875\n",
            "Epoch 94/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - accuracy: 0.9351 - loss: 0.2549 - val_accuracy: 0.0000e+00 - val_loss: 21.3822\n",
            "Epoch 95/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - accuracy: 0.9405 - loss: 0.2071 - val_accuracy: 0.0241 - val_loss: 21.1078\n",
            "Epoch 96/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 48ms/step - accuracy: 0.9519 - loss: 0.1176 - val_accuracy: 0.0241 - val_loss: 21.5965\n",
            "Epoch 97/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - accuracy: 0.9779 - loss: 0.0967 - val_accuracy: 0.0241 - val_loss: 21.7814\n",
            "Epoch 98/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 49ms/step - accuracy: 0.9528 - loss: 0.2381 - val_accuracy: 0.0241 - val_loss: 20.6033\n",
            "Epoch 99/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - accuracy: 0.9779 - loss: 0.0933 - val_accuracy: 0.0241 - val_loss: 20.9647\n",
            "Epoch 100/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.9673 - loss: 0.1043 - val_accuracy: 0.0241 - val_loss: 21.8548\n",
            "\n",
            "Evaluation of LSTM Model for 2-Digit Bottom:\n",
            "Test Loss (2-Digit Bottom): 17.6704\n",
            "Test Accuracy (2-Digit Bottom): 0.0097\n",
            "\n",
            "Training separate LSTM models for each digit of Prize 1 (3D)...\n",
            "\n",
            "Training LSTM Model for Prize 1 (3D) - Digit 1 (Hundred)...\n",
            "Test Accuracy (Prize 1 - Digit 1): 0.1262\n",
            "Training LSTM Model for Prize 1 (3D) - Digit 2 (Ten)...\n",
            "Test Accuracy (Prize 1 - Digit 2): 0.1359\n",
            "Training LSTM Model for Prize 1 (3D) - Digit 3 (Unit)...\n",
            "Test Accuracy (Prize 1 - Digit 3): 0.0680\n",
            "\n",
            "Training separate Random Forest models for each digit...\n",
            "Training Random Forest for 2-Digit Bottom - Digit 1...\n",
            "Test Accuracy (RF 2-Digit Bottom - Digit 1): 0.1456\n",
            "Training Random Forest for 2-Digit Bottom - Digit 2...\n",
            "Test Accuracy (RF 2-Digit Bottom - Digit 2): 0.0583\n",
            "Training Random Forest for Prize 1 (3D) - Digit 1...\n",
            "Test Accuracy (RF Prize 1 (3D) - Digit 1): 0.0583\n",
            "Training Random Forest for Prize 1 (3D) - Digit 2...\n",
            "Test Accuracy (RF Prize 1 (3D) - Digit 2): 0.0971\n",
            "Training Random Forest for Prize 1 (3D) - Digit 3...\n",
            "Test Accuracy (RF Prize 1 (3D) - Digit 3): 0.1068\n",
            "\n",
            "Model training complete.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ---- 5. การประเมินและการทำนาย ----\n",
        "\n",
        "print(\"\\n--- Model Evaluation Summary ---\")\n",
        "\n",
        "if KERAS_AVAILABLE:\n",
        "    print(\"\\nLSTM Model for 2-Digit Bottom:\")\n",
        "    loss_bottom2, accuracy_bottom2 = model_bottom2_lstm.evaluate(X_test_lstm, y_bottom2_test_categorical, verbose=0)\n",
        "    print(f\"  Test Loss: {loss_bottom2:.4f}\")\n",
        "    print(f\"  Test Accuracy: {accuracy_bottom2:.4f}\")\n",
        "\n",
        "    print(\"\\nLSTM Models for Prize 1 (3D) Digits:\")\n",
        "    loss_d1, acc_d1 = model_prize1_3d_digit1_lstm.evaluate(X_test_lstm, y_prize1_3d_d1_test_categorical, verbose=0)\n",
        "    print(f\"  Test Accuracy (Digit 1 - Hundred): {acc_d1:.4f}\")\n",
        "    loss_d2, acc_d2 = model_prize1_3d_digit2_lstm.evaluate(X_test_lstm, y_prize1_3d_d2_test_categorical, verbose=0)\n",
        "    print(f\"  Test Accuracy (Digit 2 - Ten): {acc_d2:.4f}\")\n",
        "    loss_d3, acc_d3 = model_prize1_3d_digit3_lstm.evaluate(X_test_lstm, y_prize1_3d_d3_test_categorical, verbose=0)\n",
        "    print(f\"  Test Accuracy (Digit 3 - Unit): {acc_d3:.4f}\")\n",
        "else:\n",
        "    print(\"LSTM models not trained as TensorFlow/Keras was not available.\")\n",
        "\n",
        "\n",
        "print(\"\\nRandom Forest Models:\")\n",
        "print(f\"  Test Accuracy (RF 2-Digit Bottom - Digit 1): {rf_b2_d1_accuracy:.4f}\")\n",
        "print(f\"  Test Accuracy (RF 2-Digit Bottom - Digit 2): {rf_b2_d2_accuracy:.4f}\")\n",
        "print(f\"  Test Accuracy (RF Prize 1 (3D) - Digit 1): {rf_p1_3d_d1_accuracy:.4f}\")\n",
        "print(f\"  Test Accuracy (RF Prize 1 (3D) - Digit 2): {rf_p1_3d_d2_accuracy:.4f}\")\n",
        "print(f\"  Test Accuracy (RF Prize 1 (3D) - Digit 3): {rf_p1_3d_d3_accuracy:.4f}\")\n",
        "\n",
        "# --- การทำนายสำหรับงวดถัดไป ---\n",
        "print(\"\\n--- Predicting for the Next Draw ---\")\n",
        "\n",
        "# ดึงข้อมูลล่าสุดเท่ากับ SEQUENCE_LENGTH สำหรับ LSTM\n",
        "# ต้องใช้ข้อมูลที่ถูก scaled แล้ว\n",
        "last_sequence_lstm = scaled_features_df.iloc[-SEQUENCE_LENGTH:].values\n",
        "last_sequence_lstm = last_sequence_lstm.reshape(1, SEQUENCE_LENGTH, X_train_lstm.shape[2]) # Reshape ให้เข้ากับ input ของ LSTM\n",
        "\n",
        "# ดึงข้อมูลฟีเจอร์ล่าสุด 1 งวด สำหรับ Random Forest\n",
        "last_feature_rf = scaled_features_df.iloc[-1:].values # ใช้ .iloc[-1:] เพื่อให้ได้ 2D array\n",
        "\n",
        "\n",
        "if KERAS_AVAILABLE:\n",
        "    # ทำนายเลข 2 ตัวล่างด้วย LSTM\n",
        "    prob_bottom2_lstm = model_bottom2_lstm.predict(last_sequence_lstm)[0]\n",
        "    predicted_bottom2_lstm_idx = np.argmax(prob_bottom2_lstm)\n",
        "    predicted_bottom2_lstm = str(predicted_bottom2_lstm_idx).zfill(2) # แปลงกลับเป็น 00-99\n",
        "    print(f\"LSTM Predicted 2-Digit Bottom: {predicted_bottom2_lstm}\")\n",
        "\n",
        "    # ทำนายเลขท้าย 3 ตัวรางวัลที่ 1 ด้วย LSTM (แต่ละหลัก)\n",
        "    prob_p1_d1_lstm = model_prize1_3d_digit1_lstm.predict(last_sequence_lstm)[0]\n",
        "    predicted_p1_d1_lstm = np.argmax(prob_p1_d1_lstm)\n",
        "\n",
        "    prob_p1_d2_lstm = model_prize1_3d_digit2_lstm.predict(last_sequence_lstm)[0]\n",
        "    predicted_p1_d2_lstm = np.argmax(prob_p1_d2_lstm)\n",
        "\n",
        "    prob_p1_d3_lstm = model_prize1_3d_digit3_lstm.predict(last_sequence_lstm)[0]\n",
        "    predicted_p1_d3_lstm = np.argmax(prob_p1_d3_lstm)\n",
        "\n",
        "    predicted_prize1_3d_lstm = f\"{predicted_p1_d1_lstm}{predicted_p1_d2_lstm}{predicted_p1_d3_lstm}\"\n",
        "    print(f\"LSTM Predicted Prize 1 (3D): {predicted_prize1_3d_lstm}\")\n",
        "else:\n",
        "    print(\"LSTM predictions skipped as TensorFlow/Keras is not available.\")\n",
        "\n",
        "\n",
        "# ทำนายเลข 2 ตัวล่างด้วย Random Forest (แต่ละหลัก)\n",
        "predicted_b2_d1_rf = rf_bottom2_d1_model.predict(last_feature_rf)[0]\n",
        "predicted_b2_d2_rf = rf_bottom2_d2_model.predict(last_feature_rf)[0]\n",
        "predicted_bottom2_rf = f\"{predicted_b2_d1_rf}{predicted_b2_d2_rf}\"\n",
        "print(f\"RF Predicted 2-Digit Bottom: {predicted_bottom2_rf}\")\n",
        "\n",
        "# ทำนายเลขท้าย 3 ตัวรางวัลที่ 1 ด้วย Random Forest (แต่ละหลัก)\n",
        "predicted_p1_3d_d1_rf = rf_prize1_3d_d1_model.predict(last_feature_rf)[0]\n",
        "predicted_p1_3d_d2_rf = rf_prize1_3d_d2_model.predict(last_feature_rf)[0]\n",
        "predicted_p1_3d_d3_rf = rf_prize1_3d_d3_model.predict(last_feature_rf)[0]\n",
        "predicted_prize1_3d_rf = f\"{predicted_p1_3d_d1_rf}{predicted_p1_3d_d2_rf}{predicted_p1_3d_d3_rf}\"\n",
        "print(f\"RF Predicted Prize 1 (3D): {predicted_prize1_3d_rf}\")\n",
        "\n",
        "# --- แนวทางการปรับปรุงเพิ่มเติม ---\n",
        "print(\"\\n--- Next Steps for Improvement ---\")\n",
        "print(\"1. **Hyperparameter Tuning:** ปรับค่า 'epochs', 'batch_size' สำหรับ LSTM, 'n_estimators' สำหรับ Random Forest\")\n",
        "print(\"2. **More Complex Features:** พิจารณาสถิติเชิงลึกอื่นๆ เช่น ช่วงห่างของตัวเลข, รูปแบบการมาของเลขเบิ้ล/เลขหาม\")\n",
        "print(\"3. **Ensemble Methods:** รวมผลการทำนายจากโมเดลหลายตัว (เช่น LSTM และ Random Forest) เพื่อให้ได้ผลลัพธ์ที่ดีขึ้น\")\n",
        "print(\"4. **Data Augmentation:** หากมีข้อมูลน้อย อาจพิจารณาเทคนิคการเพิ่มข้อมูล\")\n",
        "print(\"5. **Model Architecture:** สำหรับ LSTM อาจลองเพิ่ม Layer, Dropout หรือใช้ Bidirectional LSTM\")\n",
        "print(\"6. **Error Analysis:** วิเคราะห์ว่าโมเดลทำนายผิดพลาดในกรณีใดบ่อยที่สุด เพื่อปรับปรุงฟีเจอร์หรือโมเดลให้ตรงจุด\")\n",
        "print(\"7. **Validation Strategy:** ใช้ TimeSeriesSplit สำหรับ Cross-validation เพื่อประเมินประสิทธิภาพโมเดลได้แม่นยำขึ้น\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OIrOS4NYVMfO",
        "outputId": "213bf142-e699-4fa0-a35f-7c458a01c456"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Model Evaluation Summary ---\n",
            "\n",
            "LSTM Model for 2-Digit Bottom:\n",
            "  Test Loss: 17.6704\n",
            "  Test Accuracy: 0.0097\n",
            "\n",
            "LSTM Models for Prize 1 (3D) Digits:\n",
            "  Test Accuracy (Digit 1 - Hundred): 0.1262\n",
            "  Test Accuracy (Digit 2 - Ten): 0.1359\n",
            "  Test Accuracy (Digit 3 - Unit): 0.0680\n",
            "\n",
            "Random Forest Models:\n",
            "  Test Accuracy (RF 2-Digit Bottom - Digit 1): 0.1456\n",
            "  Test Accuracy (RF 2-Digit Bottom - Digit 2): 0.0583\n",
            "  Test Accuracy (RF Prize 1 (3D) - Digit 1): 0.0583\n",
            "  Test Accuracy (RF Prize 1 (3D) - Digit 2): 0.0971\n",
            "  Test Accuracy (RF Prize 1 (3D) - Digit 3): 0.1068\n",
            "\n",
            "--- Predicting for the Next Draw ---\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 467ms/step\n",
            "LSTM Predicted 2-Digit Bottom: 76\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 506ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 325ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 319ms/step\n",
            "LSTM Predicted Prize 1 (3D): 987\n",
            "RF Predicted 2-Digit Bottom: 25\n",
            "RF Predicted Prize 1 (3D): 157\n",
            "\n",
            "--- Next Steps for Improvement ---\n",
            "1. **Hyperparameter Tuning:** ปรับค่า 'epochs', 'batch_size' สำหรับ LSTM, 'n_estimators' สำหรับ Random Forest\n",
            "2. **More Complex Features:** พิจารณาสถิติเชิงลึกอื่นๆ เช่น ช่วงห่างของตัวเลข, รูปแบบการมาของเลขเบิ้ล/เลขหาม\n",
            "3. **Ensemble Methods:** รวมผลการทำนายจากโมเดลหลายตัว (เช่น LSTM และ Random Forest) เพื่อให้ได้ผลลัพธ์ที่ดีขึ้น\n",
            "4. **Data Augmentation:** หากมีข้อมูลน้อย อาจพิจารณาเทคนิคการเพิ่มข้อมูล\n",
            "5. **Model Architecture:** สำหรับ LSTM อาจลองเพิ่ม Layer, Dropout หรือใช้ Bidirectional LSTM\n",
            "6. **Error Analysis:** วิเคราะห์ว่าโมเดลทำนายผิดพลาดในกรณีใดบ่อยที่สุด เพื่อปรับปรุงฟีเจอร์หรือโมเดลให้ตรงจุด\n",
            "7. **Validation Strategy:** ใช้ TimeSeriesSplit สำหรับ Cross-validation เพื่อประเมินประสิทธิภาพโมเดลได้แม่นยำขึ้น\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNEAZDmBqNWbSgsBQOLkDKZ",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}